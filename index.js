const Groq = require('groq-sdk');

const groq = new Groq({ apiKey: process.env.GROQ_API_KEY });
async function main() {
  const chatCompletion = await groq.chat.completions.create({
    "messages": [
      {
        "role": "system",
        "content": "Basic Terminology: Graphs, nodes, edges, paths, cycles, connectivity\nGraph Types: Directed, undirected, weighted, unweighted, bipartite, trees, and DAGs\nGraph Representation: Adjacency matrix, adjacency list\nTraversal Algorithms: Depth-First Search (DFS) and Breadth-First Search (BFS)\nShortest Path Algorithms: Dijkstra’s algorithm, Bellman-Ford algorithm\nMinimum Spanning Tree (MST): Prim’s algorithm, Kruskal’s algorithm\nFlow Networks: Ford-Fulkerson algorithm, Max-flow min-cut theorem\n\n\nBasic Terminology:\n\nWhat is a Graph?\nA graph is a non-linear kind of data structure made up of nodes or vertices and edges. The edges connect any two nodes in the graph, and the nodes are also known as vertices\nWe can also define  graph G as an ordered set (V, E), where V(G) represents the set of vertices and E(G) represents the edges that connect these vertices.\nThe above figure shows a graph with\n\n                                  V(G) = {A, B, C, D and E}    and\n                                   E(G) = {(A, B), (B, C), (A, D), (B, D), (D, E), (C, E)}.\n\n Note that there are five vertices or nodes and six edges in the graph\n\n\n\n\n Adjacent nodes or neighbours:\n For every edge, e = (u, v) that connects nodes u and v, the nodes u and v are the end-points and are said to be the adjacent nodes or neighbours.\n\n Degree of a node:\n Degree of a node u, deg(u), is the total number of edges containing the node u. If deg(u) = 0, it means that u does not belong to any edge and such a node is known as an  isolated node.\nIndegree of the node is the number of arriving edges to a node. \nOutdegree of the node is the number of departing edges to a node. \n\nNote:  a self-loop is counted twice \n\nPath: \nA path of length ‘n’ from node ‘u’ to node ‘v’ is defined as sequence of n+1 nodes.\nP(u,v)=(v0,v1,v2,v3…….vn)\nClosed path:\n A path P is known as a closed path if the edge has the same end-points. That is, if v0 = vn . \n\nSimple path:\n A path P is known as a simple path if all the nodes in the path are distinct with an exception that v0 may be equal to vn . If v0 = vn , then the path is called a closed simple path.\n\n Cycle:\n A path in which the first and the last vertices are same. A simple cycle has no repeated edges or vertices (except the first and last vertices).\n\n\n\n\n\n\n\n\n\n\n//figure//\n\n\nGraph Types: \nDirected, undirected, weighted, unweighted, bipartite, trees, and DAGs\n\n\n1. Undirected Graph\nA graph in which edges do not have any direction. That is the nodes are unordered pairs in the definition of every edge. \n\nCharacteristics of an Undirected Graph:\nEdges in an undirected graph are bidirectional in nature.\nIn an undirected graph, there is no concept of a “parent” or “child” vertex as there is no direction to the edges.\nAn undirected graph may contain loops, which are edges that connect a vertex to itself.\nDegree of each vertex is the same as the total no of edges connected to it.\nApplications:\nPeer-to-Peer Networks: In file-sharing or communication networks where any peer can communicate with any other without directionality.\nSocial Networks (Friendships): When friendships are mutual, they are best represented as undirected edges between nodes (individuals).\nCollaborative Filtering in Recommendations: Represents users and items with edges indicating associations, with no directed flow needed.\n\n\n\n\n2. Directed Graph\nA graph in which edge has direction. That is the nodes are ordered pairs in the definition of every edge.\n\n A directed graph G, also known as a digraph, is a graph in which every edge has a direction assigned to it.\n An edge of a directed graph is given as an ordered pair (u, v) of nodes in G.For an edge (u, v), \nThe edge begins at u and terminates at v. \nu is known as the origin or initial point of e. Correspondingly, v is known as the destination or terminal point of e. \n u is the predecessor of v. Correspondingly, v is the successor of u. \n Nodes u and v are adjacent to each other.\n\n\nTerminology of a Directed graph \n\nOut-degree of a node The out-degree of a node u, written as outdeg(u), is the number of edges that originate at u.\n In-degree of a node \nThe in-degree of a node u, written as indeg(u), is the number of edges that terminate at u.\n Degree of a node \nThe degree of a node, written as deg(u), is equal to the sum of in-degree and out-degree of that node. Therefore, deg(u) = indeg(u) + outdeg(u).\n Isolated vertex A vertex with degree zero. Such a vertex is not an end-point of any edge.\n Pendant vertex (also known as leaf vertex) A vertex with degree one.\n Cut vertex A vertex which when deleted would disconnect the remaining graph.\n Source A node u is known as a source if it has a positive out-degree but a zero in-degree.\n Sink A node u is known as a sink if it has a positive in-degree but a zero out-degree.\n Reachability A node v is said to be reachable from node u, if and only if there exists a (directed) path from node u to node v. For example, if you consider the directed graph given in Fig. 13.5(a), you will observe that node D is reachable from node A.\nApplications:\nSocial networks: Social networks are often modeled as directed graphs, where each person is a vertex and relationships such as friendships or following are represented as edges.\n Transportation networks: Transportation systems such as roads, airports, or subway systems can be modeled as directed graphs, with vertices representing locations and edges representing connections between them.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3. Connected Graph\nThe graph in which from one node we can visit any other node in the graph is known as a connected graph. \nApplications:\nPower Grids: Ensures that power can reach any point from any source, making the network more resilient.\nRoad Networks: Helps in urban planning to ensure accessibility across the city.\n\n\n\n\n4. Disconnected Graph\nThe graph in which at least one node is not reachable from a node is known as a disconnected graph.\nApplications:\nClustered Social Networks: Models social groups that are isolated or have minimal interaction with others.\nDistributed Computing: Represents disconnected network partitions that can be processed independently for parallel computation.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5. Complete Graph\nThe graph in which from each node there is an edge to each other node.\n\n\n\nApplications:\n\n\nNetwork analysis: The characteristics of other graphs, such as clustering, connectedness, or shortest path length, can be measured against the attributes of complete graphs.\nProject Planning: In scenarios where every task (node) has dependencies on every other, representing complete interdependencies.\n6. Cyclic Graph\nA graph containing at least one cycle is known as a Cyclic graph.\nApplications:\nSupply Chain Loops: Used to represent cyclic dependencies, such as feedback loops in inventory and demand.\nControl Systems: Models feedback loops where outputs influence inputs in systems like robotics or automatic controls.\n\n\n\n\n\n7.A Directed Acyclic Graph (DAG) is a directed graph that does not contain any cycles.\n\n\nApplications:\nTask Scheduling: Directed Acyclic Graphs (DAGs) model dependencies in workflows, such as in project management (e.g., PERT, Gantt charts).\nVersion Control Systems: Used to track revisions and branches, ensuring no circular dependencies.\n\n\n\n\n\n\n\n\n\n\n8. Bipartite Graph\nA graph in which vertex can be divided into two sets such that vertex in each set does not contain any edge between them.\nApplications:\nRecommendation Systems: Matches users with items, where edges signify preferences, such as movies or products.\nMatching Problems: Applied in job assignments or school admissions, connecting applicants to jobs/schools with certain criteria.\n\n\n\n\n\n\n\n9. Weighted Graph\n A graph in which the edges are already specified with suitable weight is known as a weighted graph. \n Weighted graphs can be further classified as directed weighted graphs and undirected weighted graphs.\n\n\nApplications:\nSpanning trees: Weighted graphs are used to find the minimum spanning tree from graph which depicts the minimal cost to traverse all nodes in the graph.\nNetwork Routing: In computer networks, where weights indicate bandwidth or latency, allowing optimized path selection.\n10. Simple Graph:\nA simple graph is a graph that does not contain more than one edge between the pair of vertices. \nIf each pair of nodes or vertices in a graph G=(V, E) has only one edge, it is a simple graph.\n As a result, there is just one edge linking two vertices, depicting one-to-one interactions between two elements.\n\nThere are four vertices  here labeled B,C,E,F. Each vertex appears to be connected to others with straight edges.\nIt is a simple graph because it does not contain any self-loops (edges connecting a vertex to itself) or multiple edges between any two vertices.\nApplications:\nSocial Networks: Represent friendships, where each edge signifies a connection without self-loops or multiple edges.\nTransportation Networks: Cities or stations as nodes connected by edges that represent direct paths without redundant links.\nGraph algorithms:\nDijkstra's Algorithm:\n\n\n\n\n\n\n\nBellman Ford's Algorithm\n\nSpanning trees\nGiven a connected graph with |V| = n vertices, a spanning tree is defined\na collection of n – 1 edges which connect all n vertices\n◦ The n vertices and n – 1 edges define a connected sub-graph\nA spanning tree is not necessarily unique\nThis graph has 16 vertices and 35 edges\n\n\nSpanning trees on weighted graphs\nThe weight of a spanning tree is the sum of the weights on all the edges\nwhich comprise the spanning tree\n◦ The weight of this spanning tree is 20\n\n\nMinimum Spanning Trees\nWhich spanning tree minimizes the weight?\n◦ Such a tree is termed a minimum spanning tree\nThe weight of this spanning tree is 14\n\nApplication\nConsider supplying power to\n◦ All circuit elements on a board\n◦ A number of loads within a building\n\n\nA minimum spanning tree will give the lowest-cost solution\nConsider attempting to find the best means of connecting a number of\nLANs\n◦ Minimize the number\nof bridges\n◦ Costs not strictly\ndependent on\ndistances\n\n\n\n\nMinimum Spanning Tree (Kruskal's)\nKruskal’s algorithm sorts the edges by weight and goes through the edges from least weight to greatest weight adding the edges to an empty\ngraph so long as the addition does not create a cycle\n\nHow to find MST using Kruskal’s algorithm?\nBelow are the steps for finding MST using Kruskal’s algorithm:\nSort all the edges in non-decreasing order of their weight. \nPick the smallest edge. Check if it forms a cycle with the spanning tree formed so far. If the cycle is not formed, include this edge. Else, discard it. \nRepeat step#2 until there are (V-1) edges in the spanning tree.\n\n\nBelow is an illustration of the above algorithm:\n\nThe graph contains 5 vertices and 10 edges. So, the minimum spanning tree formed will be having (5 – 1) = 4 edges. \n\n\n\n\nAfter sorting:\n\n\nWeight\nSource\nDestination\n13\n0\n2\n13\n1\n4\n13\n3\n1\n13\n0\n3\n14\n2\n4\n19\n2\n3\n19\n3\n4\n22\n0\n4\n27\n1\n2\n28\n0\n1\n\nNow pick all edges one by one from the sorted list of edges . Its illustrated below:\n//VIDEO//\nFollowing are the edges in the constructed MST\n0 -- 2 == 13\n0 -- 3 == 13\n3 -- 1 == 13\n1 -- 4 == 13\n\n\nMinimum Cost Spanning Tree: 52\n\nTime Complexity: O(E * logE) or O(E * logV) \nSorting of edges takes O(E * logE) time. \nAfter sorting, we iterate through all edges and apply the find-union algorithm. The find and union operations can take at most O(logV) time.\nSo overall complexity is O(E * logE + E * logV) time. \nThe value of E can be at most O(V2), so O(logV) and O(logE) are the same. Therefore, the overall time complexity is O(E * logE) or O(E*logV)\nAuxiliary Space: O(V + E), where V is the number of vertices and E is the number of edges in the graph.\n\n\n\n\n\nMinimum Spanning Tree (Prim's)\nPrim’s algorithm for finding the minimum spanning tree states:\nThe algorithm starts with an empty spanning tree. The idea is to maintain two sets of vertices. The first set contains the vertices already included in the MST, and the other set contains the vertices not yet included. At every step, it considers all the edges that connect the two sets and picks the minimum weight edge from these edges. After picking the edge, it moves the other endpoint of the edge to the set containing MST. \n\n\nHow does Prim’s Algorithm Work? \nThe working of Prim’s algorithm can be described by using the following steps:\nStep 1: Determine an arbitrary vertex as the starting vertex of the MST.\nStep 2: Follow steps 3 to 5 till there are vertices that are not included in the MST (known as fringe vertex).\nStep 3: Find edges connecting any tree vertex with the fringe vertices.\nStep 4: Find the minimum among these edges.\nStep 5: Add the chosen edge to the MST if it does not form any cycle.\nStep 6: Return the MST and exit\nConsider the following graph as an example for which we need to find the Minimum Spanning Tree (MST).\n\n\n\n\nFirstly, we select an arbitrary vertex that acts as the starting vertex of the Minimum Spanning Tree. Here we have selected vertex 0 as the starting vertex.\n\n\nWe can see the illustration below to understand better:\n//video//\nOutput\n110\n\n\n\n\nComplexity Analysis of Prim’s Algorithm:\nTime Complexity: O(E*log(E)) where E is the number of edges\nAuxiliary Space: O(V^2) where V is the number of vertex\nPrim’s algorithm for finding the minimum spanning tree (MST):\nAdvantages:\nPrim’s algorithm is guaranteed to find the MST in a connected, weighted graph.\nIt has a time complexity of O(E log V) using a binary heap or Fibonacci heap, where E is the number of edges and V is the number of vertices.\nIt is a relatively simple algorithm to understand and implement compared to some other MST algorithms.\nDisadvantages:\nLike Kruskal’s algorithm, Prim’s algorithm can be slow on dense graphs with many edges, as it requires iterating over all edges at least once.\nPrim’s algorithm relies on a priority queue, which can take up extra memory and slow down the algorithm on very large graphs.\nThe choice of starting node can affect the MST output, which may not be desirable in some applications.\n\n\n\n\n\n\nBreadth-First Search (BFS)\nDepth-First Search (DFS)\nDijkstra:\nDijkstra’s algorithm\nDijkstra’s algorithm solves the single-source shortest path problem\n◦ It is very similar to Prim’s algorithm\n◦ Assumption: all the weights are positive\n\n\nLike Prim’s algorithm,\nWe initially don’t know the distance to any vertex except the initial vertex\nWe require an array of distances, all initialized to infinity except for the source\nvertex, which is initialized to 0\nEach time we visit a vertex, we will examine all adjacent vertices\nWe need to track visited vertices—a Boolean table of size |V|\nWe need an array of previous vertices, all initialized to null\n\n\nThus, we will iterate |V| times:\n◦ Find that unvisited vertex v that has a minimum distance to it\n◦ Mark it as having been visited\n◦ Consider every adjacent vertex w that is unvisited:\n◦ Is the distance to v plus the weight of the edge (v, w) less than our currently known shortest\ndistance to w\n◦ If so, update the shortest distance to w and record v as the previous pointer\n\n\n◦ Continue iterating until all vertices are visited or all remaining vertices have a\ndistance to them of infinity\nGiven a weighted graph and a source vertex in the graph, find the shortest paths from the source to all the other vertices in the given graph.\nNote: The given graph does not contain any negative edge.\n\n\nTo understand the Dijkstra’s Algorithm let's take a graph and find the shortest path from source to all nodes.\nConsider below graph and src = 0\n\n\n\nWe can see the illustration below to understand better:\n//video//\n\n\nVertex  Distance from Source\n0          0\n1          1\n2          3\n3          2\n4          3\n5          4\n6          6\n7          5\nBy using Priority Queue:\nTime Complexity: O((V+E)logV)\nAuxiliary Space: O(V+E)\nApplications of Dijkstra’s Algorithm:\nGoogle maps uses Dijkstra algorithm to show shortest distance between source and destination.\nIn computer networking , Dijkstra’s algorithm forms the basis for various routing protocols, such as OSPF (Open Shortest Path First) and IS-IS (Intermediate System to Intermediate System).\nTransportation and traffic management systems use Dijkstra’s algorithm to optimize traffic flow, minimize congestion, and plan the most efficient routes for vehicles.\nAirlines use Dijkstra’s algorithm to plan flight paths that minimize fuel consumption, reduce travel time.\nDijkstra’s algorithm is applied in electronic design automation for routing connections on integrated circuits and very-large-scale integration (VLSI) chips.\n\n\n\n\nBellman–Ford Algorithm\nBellman-Ford is a single source shortest path algorithm that determines the shortest path between a given source vertex and every other vertex in a graph. This algorithm can be used on both weighted and unweighted graphs.\n\nA Bellman-Ford algorithm is also guaranteed to find the shortest path in a graph, similar to Dijkstra’s algorithm. Although Bellman-Ford is slower than Dijkstra’s algorithm, it is capable of handling graphs with negative edge weights, which makes it more versatile. \n\nBellman-Ford is also capable of detecting negative cycles, which is an important feature.\nPrinciple of Relaxation of Edges for Bellman-Ford:\nIt states that for the graph having N vertices, all the edges should be relaxed N-1 times to compute the single source shortest path.\nIn order to detect whether a negative cycle exists or not, relax all the edge one more time and if the shortest distance for any node reduces then we can say that a negative cycle exists. In short if we relax the edges N times, and there is any change in the shortest distance of any node between the N-1th and Nth relaxation than a negative cycle exists, otherwise not exist.\n\nLet’s suppose we have a graph which is given below and we want to find whether there exists a negative cycle or not using Bellman-Ford.\n\nAlgorithm to Find Negative Cycle in a Directed Weighted Graph Using Bellman-Ford:\nInitialize distance array dist[] for each vertex ‘v‘ as dist[v] = INFINITY.\nAssume any vertex (let’s say ‘0’) as source and assign dist = 0.\nRelax all the edges(u,v,weight) N-1 times as per the below condition:\ndist[v] = minimum(dist[v], distance[u] + weight)\nNow, Relax all the edges one more time i.e. the Nth time and based on the below two cases we can detect the negative cycle:\nCase 1 (Negative cycle exists): For any edge(u, v, weight), if dist[u] + weight < dist[v]\nCase 2 (No Negative cycle) : case 1 fails for all the edges.\nWe can understand better  by the simulation below:\n//video//\nVertex  Distance from Source\n0          0\n1          9\n2          75\n3          28\n4          51\n5          4\n6          6\n7          51\n\nComplexity Analysis of Bellman-Ford Algorithm:\nTime Complexity \nBest Case: O(E),\nAverage Case: O(V*E)\nWorst Case: O(V*E)\nTime Complexity when graph is disconnected:\nAll the cases: O(E*(V^2))\nAuxiliary Space: O(V), where V is the number of vertices in the graph.\nBellman Ford’s Algorithm Applications:\nNetwork Routing: Bellman-Ford is used in computer networking to find the shortest paths in routing tables, helping data packets navigate efficiently across networks.\nGPS Navigation: GPS devices use Bellman-Ford to calculate the shortest or fastest routes between locations, aiding navigation apps and devices.\nTransportation and Logistics: Bellman-Ford’s algorithm can be applied to determine the optimal paths for vehicles in transportation and logistics, minimizing fuel consumption and travel time.\nGame Development: Bellman-Ford can be used to model movement and navigation within virtual worlds in game development, where different paths may have varying costs or obstacles.\nRobotics and Autonomous Vehicles: The algorithm aids in path planning for robots or autonomous vehicles, considering obstacles, terrain, and energy consumption.\nDrawback of Bellman Ford’s Algorithm:\nBellman-Ford algorithm will fail if the graph contains any negative edge cycle\n\n\nBreadth First Search:\nBreadth First Search (BFS) is a fundamental graph traversal algorithm. It begins with a node, then first traverses all its adjacent. Once all adjacent are visited, then their adjacent are traversed. \nBFS from a Given Source:\nThe algorithm starts from a given source and explores all reachable vertices from the given source. It is similar to the Breadth-First Traversal of a tree. Like tree, we begin with the given source (in tree, we begin with root) and traverse vertices level by level using a queue data structure. The only catch here is that, unlike trees, graphs may contain cycles, so we may come to the same node again. To avoid processing a node more than once, we use a boolean visited array.\nInitialization: Enqueue the given source vertex into a queue and mark it as visited.\nExploration: While the queue is not empty:\nDequeue a node from the queue and visit it (e.g., print its value).\nFor each unvisited neighbor of the dequeued node:\nEnqueue the neighbor into the queue.\nMark the neighbor as visited.\nTermination: Repeat step 2 until the queue is empty.\nThis algorithm ensures that all nodes in the graph are visited in a breadth-first manner, starting from the starting node.\nWe can understand BFS for the gaph below:\n\n We can understand better by the simulation below:\n//video//\nOutput\nBFS starting from 0 : \n0 → 1 → 4 → 2 → 5 → 8 → 3 → 6 → 10 → 9 → 7 → 11 → 12\nTime Complexity: O(V+E), where V is the number of nodes and E is the number of edges.\nAuxiliary Space: O(V)\n\n\nDepth First Traversal:\nDepth First Traversal (or DFS) for a graph is similar to Depth First Traversal of a tree. Like trees, we traverse all adjacent vertices one by one. When we traverse an adjacent vertex, we completely finish the traversal of all vertices reachable through that adjacent vertex. After we finish traversing one adjacent vertex and its reachable vertices, we move to the next adjacent vertex and repeat the process. \nLets consider the following grAPH:\n\nWe can understand dfs better with the simulation below:\n//video//\nOutput\nDFS from source: 1\n1 2 0 3 4\nTime complexity: O(V + E), where V is the number of vertices and E is the number of edges in the graph.\nAuxiliary Space: O(V + E), since an extra visited array of size V is required, And stack size for recursive calls to DFSRec function\n\n\nUsers Collection : Store user profile information, achievements, and progress.\nLearning-Materials Collection : Store tutorials, explanations, and related content.\nExercises Collection : Store exercises, solutions, and feedback.\nBadges Collection : Store badges or certifications awarded to users.\n\n\n\n\n"
      },
      {
        "role": "user",
        "content": "user"
      },
      {
        "role": "assistant",
        "content": "I'm happy to help with any graph-related questions you may have. Whether you need further explanations on graph algorithms, graph types, or graph traversal methods, feel free to ask."
      }
    ],
    "model": "llama-3.1-70b-versatile",
    "temperature": 1,
    "max_tokens": 1024,
    "top_p": 1,
    "stream": true,
    "stop": null
  });

  for await (const chunk of chatCompletion) {
    process.stdout.write(chunk.choices[0]?.delta?.content || '');
  }
}

main();